# For the meanings of parameters, execute: AI_models/run_bind_transformer.py -h.
[common]
data_dir = test
train_output_dir = bind_transformer/checkpoints
pipeline_output_dir = bind_transformer/pipeline
seed = 63036
# device =
log_level = WARNING

[dataset]
validation_ratio = 0.1
test_ratio = 0.1

[data loader]
batch_size = 1000

[optimizer]
optimizer = adamw_torch
learning_rate = 0.001

[scheduler]
scheduler = linear
num_epochs = 30.0
warmup_ratio = 0.05

[roformer]
protein_animo_acids_vocab_size = 21
protein_secondary_structure_vocab_size = 12
protein_coarse_grained_size = 10
protein_max_position_embeddings = 3072
DNA_vocab_size = 6
DNA_max_position_embeddings = 128
embedding_size = 512
hidden_size = 256
num_attention_heads = 4
num_hidden_layers = 4
chunk_size_feed_forward = 0
intermediate_size = 1024
hidden_act = gelu
hidden_dropout_prob = 0.1
attention_probs_dropout_prob = 0.1
initializer_range = 0.02
layer_norm_eps = 1e-12
rotary_value = False
pos_weight = 1
