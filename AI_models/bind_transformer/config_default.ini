# For the meanings of parameters, execute: AI_models/run_bind_transformer.py -h.
[common]
data_dir = test
train_output_dir = AI_models/bind_transformer/checkpoints
pipeline_output_dir = AI_models/bind_transformer/pipeline
seed = 63036
# device =
log_level = WARNING

[dataset]
validation_ratio = 0.1
test_ratio = 0.1

[data loader]
batch_size = 1000

[optimizer]
optimizer = adamw_torch
learning_rate = 0.001

[scheduler]
scheduler = linear
num_epochs = 30.0
warmup_ratio = 0.05

[roformer]
vocab_size = 24
hidden_size = 256
num_hidden_layers = 4
num_attention_heads = 4
intermediate_size = 1024
hidden_dropout_prob = 0.1
attention_probs_dropout_prob = 0.1
max_position_embeddings = 64
pos_weight = 1
